{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbbedd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, precision_recall_curve, auc\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946532b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_raw[FINAL_FEAT_v2]\n",
    "y = y_raw.values.reshape(30000,)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b3a601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define modeling pipeline\n",
    "model = LogisticRegression(max_iter=1000, class_weight = 'balanced')\n",
    "\n",
    "pipeline = Pipeline(steps=[('model', model)])\n",
    "\n",
    "# define cross-validation criteria. RepeatedStratifiedKFold automatially takes care of the class imbalance while splitting\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\n",
    "# fit and evaluate the logistic regression pipeline with cross-validation as defined in cv\n",
    "scores = cross_val_score(pipeline, X_train, y_train, scoring = 'roc_auc', cv = cv)\n",
    "AUROC = np.mean(scores)\n",
    "GINI = AUROC * 2 - 1\n",
    "\n",
    "# print the mean AUROC score and Gini\n",
    "print('Mean AUROC: %.4f' % (AUROC))\n",
    "print('Gini: %.4f' % (GINI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ede043",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb51be20",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = X_train.columns.values\n",
    "# Create a summary table of our logistic regression model\n",
    "summary_table = pd.DataFrame(columns = ['Feature name'], data = feature_name)\n",
    "# Create a new column in the dataframe, called 'Coefficients', with row values the transposed coefficients from the 'LogisticRegression' model\n",
    "summary_table['Coefficients'] = np.transpose(pipeline['model'].coef_)\n",
    "# Increase the index of every row of the dataframe with 1 to store our model intercept in 1st row\n",
    "summary_table.index = summary_table.index + 1\n",
    "# Assign our model intercept to this new row\n",
    "summary_table.loc[0] = ['Intercept', pipeline['model'].intercept_[0]]\n",
    "# Sort the dataframe by index\n",
    "summary_table.sort_index(inplace = True)\n",
    "# summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abee8dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table[\"coff_mag\"] = abs(summary_table.Coefficients)\n",
    "summary_table.sort_values('coff_mag', ascending= False, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531c5976",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(13, 7))\n",
    "plt.xticks(rotation=60)\n",
    "sns.lineplot(x = 'Feature name' , y = 'coff_mag', data= summary_table, ax = ax, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aafbb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e763a167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make preditions on our test set\n",
    "y_hat_test = pipeline.predict(X_test)\n",
    "# get the predicted probabilities\n",
    "y_hat_test_proba = pipeline.predict_proba(X_test)\n",
    "# select the probabilities of only the positive class (class 1 - default) \n",
    "y_hat_test_proba = y_hat_test_proba[:][: , 1]\n",
    "\n",
    "# we will now create a new DF with actual classes and the predicted probabilities\n",
    "# create a temp y_test DF to reset its index to allow proper concaternation with y_hat_test_proba\n",
    "y_test_temp = pd.DataFrame(y_test.copy())\n",
    "y_test_temp.reset_index(drop = True, inplace = True)\n",
    "y_test_proba = pd.concat([y_test_temp, pd.DataFrame(y_hat_test_proba)], axis = 1)\n",
    "# check the shape to make sure the number of rows is same as that in y_test\n",
    "# y_test_proba.shape\n",
    "\n",
    "# Rename the columns\n",
    "y_test_proba.columns = ['y_test_class_actual', 'y_hat_test_proba']\n",
    "# Makes the index of one dataframe equal to the index of another dataframe.\n",
    "y_test_proba.index = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fce0b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign a threshold value to differentiate good with bad\n",
    "tr = 0.5\n",
    "# crate a new column for the predicted class based on predicted probabilities and threshold\n",
    "# We will determine this optimat threshold later in this project\n",
    "y_test_proba['y_test_class_predicted'] = np.where(y_test_proba['y_hat_test_proba'] > tr, 1, 0)\n",
    "# create the confusion matrix\n",
    "confusion_matrix(y_test_proba['y_test_class_actual'], y_test_proba['y_test_class_predicted'], normalize = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749f3cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3897ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get the values required to plot a ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test_proba['y_test_class_actual'], y_test_proba['y_hat_test_proba'])\n",
    "# plot the ROC curve\n",
    "plt.plot(fpr, tpr)\n",
    "# plot a secondary diagonal line, with dashed line style and black color to represent a no-skill classifier\n",
    "plt.plot(fpr, fpr, linestyle = '--', color = 'k')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2642874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e185d026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335b1df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Area Under the Receiver Operating Characteristic Curve (AUROC) on our test set\n",
    "AUROC = roc_auc_score(y_test_proba['y_test_class_actual'], y_test_proba['y_hat_test_proba'])\n",
    "AUROC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da70c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# draw a PR curve\n",
    "# calculate the no skill line as the proportion of the positive class\n",
    "no_skill = len(y_test[y_test == 1]) / len(y)\n",
    "# plot the no skill precision-recall curve\n",
    "plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "\n",
    "# calculate inputs for the PR curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test_proba['y_test_class_actual'], y_test_proba['y_hat_test_proba'])\n",
    "# plot PR curve\n",
    "plt.plot(recall, precision, marker='.', label='Logistic')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.title('PR curve');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc36820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f58ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate PR AUC\n",
    "auc_pr = auc(recall, precision)\n",
    "auc_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287354f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041550d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ab53f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d26733b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d30c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
